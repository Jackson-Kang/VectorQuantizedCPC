training:
    batch_size: 32
    sample_frames: 32
    n_steps: 160000
    optimizer:
        lr: 4e-4
    scheduler:
        milestones:
            - 50000
            - 75000
            - 100000
            - 125000
        gamma: 0.5
    checkpoint_interval: 5000
    n_workers: 8